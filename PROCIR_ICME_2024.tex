% Template for Elsevier CRC journal article
% version 1.2 dated 17 May 2021

% This file (c) 2009-2021 Elsevier Ltd.  Modifications may be freely made,
% provided the edited file is saved under a different name

% This file contains modifications for Transportation Research Procedia

% Changes since version 1.1
% - added "procedia" option compliant with ecrc.sty version 1.2a
%   (makes the layout approximately the same as the Word CRC template)
% - added example for generating copyright line in abstract

%-----------------------------------------------------------------------------------

%% This template uses the elsarticle.cls document class and the extension package ecrc.sty
%% For full documentation on usage of elsarticle.cls, consult the documentation "elsdoc.pdf"
%% Further resources available at http://www.elsevier.com/latex

%-----------------------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                          %%
%% Important note on usage                                  %%
%% -----------------------                                  %%
%% This file should normally be compiled with PDFLaTeX      %%
%% Using standard LaTeX should work but may produce clashes %%
%%                                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% The '3p' and 'times' class options of elsarticle are used for Elsevier CRC
%% The 'procedia' option causes ecrc to approximate to the Word template
\documentclass[5p,times,procedia]{elsarticle}
\flushbottom

%% The `ecrc' package must be called to make the CRC functionality available
\usepackage{ecrc}
%\usepackage{amsmath}


%% The ecrc package defines commands needed for running heads and logos.
%% For running heads, you can set the journal name, the volume, the starting page and the authors

%% set the volume if you know. Otherwise `00'
\volume{00}

%% set the starting page if not 1
\firstpage{1}

%% Give the name of the journal
\journalname{Procedia CIRP}

%% Give the author list to appear in the running head
%% Example \runauth{C.V. Radhakrishnan et al.}
\runauth{B. Bertschinger et al.}

%% The choice of journal logo is determined by the \jid and \jnltitlelogo commands.
%% A user-supplied logo with the name <\jid>logo.pdf will be inserted if present.
%% e.g. if \jid{yspmi} the system will look for a file yspmilogo.pdf
%% Otherwise the content of \jnltitlelogo will be set between horizontal lines as a default logo

%% Give the abbreviation of the Journal.
\jid{trpro}

%% Give a short journal name for the dummy logo (if needed)
%\jnltitlelogo{Transportation Research}

%% Hereafter the template follows `elsarticle'.
%% For more details see the existing template files elsarticle-template-harv.tex and elsarticle-template-num.tex.

%% Elsevier CRC generally uses a numbered reference style
%% For this, the conventions of elsarticle-template-num.tex should be followed (included below)
%% If using BibTeX, use the style file elsarticle-num.bst

%% End of ecrc-specific commands
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% The amssymb package provides various useful mathematical symbols

\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%\biboptions{authoryear}

% \biboptions{}

% if you have landscape tables
\usepackage[figuresright]{rotating}
%\usepackage{harvard}
% put your own definitions here:x
%   \newcommand{\cZ}{\cal{Z}}
%   \newtheorem{def}{Definition}[section]
%   ...

% add words to TeX's hyphenation exception list
%\hyphenation{author another created financial paper re-commend-ed Post-Script}

% declarations for front matter

\usepackage[bookmarks=false]{hyperref}
    \hypersetup{colorlinks,
      linkcolor=blue,
      citecolor=blue,
      urlcolor=blue}
      
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{subcaption}
%\usepackage{kbordermatrix}
\usepackage{tikz}
\usepackage{relsize}
\usepackage{lipsum}

\AtBeginDocument{%
	\addtolength\abovedisplayskip{-1.5\baselineskip}%
	\addtolength\belowdisplayskip{-1.0\baselineskip}%
	\addtolength\abovedisplayshortskip{-2.0\baselineskip}%
	\addtolength\belowdisplayshortskip{-1.0\baselineskip}%
}


\begin{document}
\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\dochead{18th CIRP Conference on Intelligent Computation in Manufacturing Engineering}%

\title{A new Software Driven External Sensor System for Industrial Robots}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\author[a]{Bernd Bertschinger\corref{*}}
\author[b]{Kathrin Hoffmann}
\author[c]{Jan Baumgärtner}
\author[b]{Gajanan Kanagalingam}
\author[c]{Jürgen Fleischer}
\author[b]{Oliver Sawodny}
\author[a]{Stephan Reichelt}
%\ead{author@institute.xxx}

\address[a]{Institute of Applied Optics, University of Stuttgart - ITO, Pfaffenwaldring 9, 70569 Stuttgart, Germany}
\address[b]{Institute for System Dynamics, University of Stuttgart - ISYS, Waldburgstr. 17/19, 70563 Stuttgart, Germany}
\address[c]{Institute of Production Science, Karlsruhe Institute of Technology - WBK, Kaiserstraße 12, 76131 Karlsruhe, Germany}

\aucores{* Bernd Bertschinger, Tel.: +49-711-685-69892. {\it E-mail address:} bernd.bertschinger@ito.uni-stuttgart.de}

\begin{abstract}
%% Text of abstract
For decades, laser tracker and working station have been the state of the art to measure externally the position disturbances in robotic systems. High system costs limit their usage for control systems in common production machines. We present details for an alternative software-driven approach. Hereby, we combine a new self-referencing, high-precision photogrammetry sensor system with a software system for camera placement layout and trajectory optimization. Furthermore, we outline the integration in a closed loop control system and corresponding strategies.
\end{abstract}

\begin{keyword}
Type your keywords here, separated by semicolons ;

%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}
%\cortext[cor1]{Corresponding author. Tel.: +0-000-000-0000 ; fax: +0-000-000-0000.}

\end{frontmatter}

%%
%% Start line numbering here if you want
%%
% \linenumbers

%% main text

\section{Introduction}

%motivation: industrial robots instead of specialized machinery, adaptable to various tasks in manufacturing, low cost \\
%limiting factor: accuracy of robot
%
%approach: software-defined planning of the robot configuration, path and trajectory
%
%result: robot motion which is the optimal solution for production precision
%
%setup: (close to?) real-time capable optical measurement system, optical markers attached to robot endeffector
%
%Relevant Errors-Model for Process Perception - Metrological Error \\
%Relevant Errors-Model for Process Planing - Dynamic Error \\
%
%System Setup

Social and ecological changes, as well as the need for
highly individualized and diversified product ranges
motivate not only to increase the efficiency of the means
of production, but also their flexibility of application.
This is addressed by the concept of Wertstromkinematik \textit{Referenz etc.}.
Herein the factory is not a static setup to produce
one set of goods, but can be dynamically reconfigured to be a generalized production floor.\\
To become a valid means of production, the system needs not only to
be more productive, but also as flexible and cost-efficient as possible. This need for flexibility in turn leads to an increase of precision, which can be used to either facilitate the production of high-precision components, for human-robot and robot-robot collaboration, as well as a trade-off for higher process speed.\\
By the current state of technology this is a dilemma, because state of the art detection system use internal sensor, which require an exceeding level of mechanical stiffness, which in turn leads to high
acquisition costs. An alternative to internal sensor system are external sensors, such laser trackers and tracking stations. The costs of these systems make them unsuitable for wide-spread production applications, but are rather used as means for calibration.\\

\subsection{Scope of this Paper}

Instead a holistic approach is needed, which combines in a software driven approach the placement and configuration of the sensor system with the trajectory generation in consideration of the kinematic control properties.s

\lipsum[1-1]

%\vspace*{2pt}
%\renewcommand{\labelenumii}{\theenumii}
%\renewcommand{\theenumii}{\theenumi.\arabic{enumii}.}
%\vspace*{8pt}
%\setlist{nolistsep}

\section{Process Perception}

Recent research indicate that multipoint photogrammetry might be a solution for a cost-sensitive high-resolution optical sensors \cite{Hartlieb_2021}.

\begin{figure}[h]
	\centering
	\includegraphics[width=\columnwidth]{graphics/error_sources.png}
	\caption{Error sources in a robotic manufacturing system. Errorsources which can be compensated using an external multipoint  sensor are marked in green.}
	\label{fig:error_sources}
\end{figure}

As can be seen in figure \ref{fig:error_sources} a Diffractive Optical Element (DOE) is used in succession of an imaging lens to create multiple linear independent optical copies of an active marker.
It has been shown \textit{add reference here} that variance of the mean psoitional detection error of these points $\sigma_{xy'}$ detected on the imaging sensor is proportional to the number of copies $n_pt$ created by the DOE.
\begin{equation}
	\sigma_{xy'}^2 = n_{pt}^{}
\end{equation}
However, this increase in planar signal detection is in itself not sufficient for high precision 3D localisation. One or more additional sensors is needed to triangulate the 2D point positions on the imaging sensors to it's point of origin in the object space. \\
For a pinhole camera system the relation between object and imaging point is determined by the camera Matrix $\mathbf{C}$, which is composed of the intrinsic $\mathbf{K}$ and  and extrinsic camera parameters $[\mathbf{R}, t]$, which comprise information about the spatial orientation, as well as information about focal width and
image scale factor. This leads to the well established colinear \cite{Luhmann2003}, whereby $l_n$ is the collinear factor, which describes the line of sight between the object and image point.

\begin{align}
	\mathbf{C} = \mathbf{K}
	\begin{bmatrix}
		\mathbf{R} & \hat{t} \\
		0 & 1 \\
	\end{bmatrix} \\
	l_{n}
	\begin{bmatrix}
		x_n' \\
		y_n' \\
		0
	\end{bmatrix}
	= \mathbf{C}
	\begin{bmatrix}
		x \\
		y \\
		z \\
		0
	\end{bmatrix}
\end{align}

Subsequently the the correspondace between object position an image points, known as triangulation, can be defined for multiple cameras according to:


\begin{equation}
	\label{eqn:Triangulation}
	\begin{bmatrix}
		x_{1}' \mathbf{C}_{3,1}^{\top} - \mathbf{C}_{1,1}^{\top}\\
		y_{1}' \mathbf{C}_{3,1}^{\top} - \mathbf{C}_{2,1}^{\top}\\
		x_{2}' \mathbf{C}_{3,2}^{\top} - \mathbf{C}_{1,2}^{\top}\\
		y_{2}' \mathbf{C}_{3,2}^{\top} - \mathbf{C}_{2,2}^{\top}\\
			\vdots \\
		x_{n}' \mathbf{C}_{3,n}^{\top} - \mathbf{C}_{1,n}^{\top}\\
		y_{n}' \mathbf{C}_{3,n}^{\top} - \mathbf{C}_{2,n}^{\top}\\
	\end{bmatrix}
	\begin{bmatrix}
		x \\
		y \\
		z \\
		1
	\end{bmatrix}
	=
	\begin{bmatrix}
		0 \\
		\vdots \\
		0
	\end{bmatrix}
\end{equation}

Whereby $C_{m,n}$ corresponds to the m-th row of the n-th camera Matrix.
In case the extrinsic and intrinsic camera paramters are fully known, the system can be solved by the least-square techniques \cite{Ahn2004}.

It is important to note that this relationship can also be described as by the notation for projective reconstruction \cite{Hartley2018}:
\begin{equation}
	\label{eqn:ProjectiveReconstruction}
	x'^{\top}\mathbf{F}x
\end{equation}
Here the fundamentak matrix $\mathbf{F}$ is a 3x3 Tensor, which scales in rank according to the number of cameras in the system. Due to the increasing complexity and computing effort, this Method is usually constraint to three cameras systems.\\
Instead of a Tensor representation the triangulation relation (\ref{eqn:triangulation}) is stated in implicit form:

\begin{equation}
	\label{eqn:ImplicitFrom}
	\begin{aligned}
		& f(\hat{\mathbf{Q}},\hat{\mathbf{M}}) \\
		& \mathbf{Q} = [\mathbf{P},\mathbf{C}]^{\top}
	\end{aligned}
\end{equation}
		
The vector of the input Quantities $\hat{\mathbf{Q}} = \left[q_1,\dots, q_{n}\right]^{\top}$ is composed of the vector of image points $\hat{\mathbf{P}} = [x'_1,y'_1, \dots ,x'_n,y'_n]^{\top}$ and the vector of camera parameters, $\hat{\mathbf{C}} = \left[ \mathbf{C}_1 , \dots , \mathbf{C}_n \right]^{\top}$, which in turn define the object point coordinates $\hat{\mathbf{M}} =  [x,y,z]^{\top}$ in cartesian form. \\
The uncertainty of the output $\hat{\mathbf{M}}$ can be approximated by the 1st order Taylor Series with regards to input parameters:

\begin{equation}
	\hat{\sigma}^2 = \sum_{i=1}^{n}\sum_{j=1}^{n} \left(\frac{\delta f}{\delta q_i}\right) \left(\frac{\delta f}{\delta q_j}\right) cov(q_i, q_j) 
\end{equation}

whereby $cov(q_i, q_j) $ is known as the covariance between two input parameters. More commonly it is known in it's more established \cite{Cox2006} form: 

\begin{equation}
	\hat{\sigma}^2 = \mathbf{J_{Q}}\mathbf{\Lambda_{Q}}\mathbf{J_{Q}}^{\top}
\end{equation}

$\mathbf{J_{Q}}$ is also known as Design- or Jacobian- Matrix of the partial derivatives of $f$ with respect to the input quantities $\mathbf{Q}$ and $\mathbf{\Lambda_Q}$ is the covariance Matrix of said  input values. \\

The uncertainty of the input parameters is directly tied to the uncertainty of the output parameters:

\begin{equation}
	\mathbf{J_{M}}\mathbf{\Lambda_{M}}\mathbf{J_{M}}^{\top} = \mathbf{J_{Q}}\mathbf{\Lambda_{Q}}\mathbf{J_{Q}}^{\top}
\end{equation}

Hereforth $\mathbf{J_{M}}$ is the Jacobian-Matrix of the partial derivatives and $\mathbf{\Lambda_{M}}$ is the Covariance Matrix with regards to the output quantities $\hat{\mathbf{M}}$.

\begin{equation}
	\mathbf{\Lambda_{M}} = \mathbf{J_{M}^{\Delta}} \left( \mathbf{J_{Q}}\mathbf{\Lambda_{Q}}\mathbf{J_{Q}}^{\top}\right) \left(\mathbf{J_{M}^{\Delta}}\right)^{\top}
\end{equation}

with $ \mathbf{J_{M}^{\Delta}} = \left( \mathbf{J_{M}^{\top}} \mathbf{J_{M}^{}} \right)^{-1}\mathbf{J_{M}^{\top}}
$ known as the pseudo inverse matrix of $\mathbf{J_M}$. \\

\subsection{Optimized Perception}
\label{error_estimate}

The design matrices for the input $\mathbf{J}_{Q}$ and output quantities $\mathbf{J}_{M}$ can be established by a various calibration processes \textit{here sources}. Usually a series of known markers is placed in the object space \cite{Luhmann2003}. In case of arbitrary camera positions the minimum number of marker needed corresponds to:

\begin{equation}
	\label{eqn:NumCalibPoints}
	\begin{aligned}
		& 	u = u_n \cdot n_{pictures} + u_p \cdot n_{points} + u_k \cdot n_{cameras} \\
		& \text{with: } u_n = 6\text{, } u_p = 3\text{, } u_k = 6 
	\end{aligned}
\end{equation}

It becomes self-evident, that an increase in cameras leads to increasing requirements for the means of calibration (\ref{eqn:NumCalibPoints}) and computational complexity, signified by the increasing rank of the fundamental matrix (\ref{eqn:ProjectiveReconstruction}). Conversly it becomes extinsively difficult to determine the metrological error 
of such as system.\\
Hence an alternative approach is needed. Instead of a single system composed of multiple cameras $n_{cam}$ a photogrametric sensor can also be described as combination of multiple idenpendent stereoscopic sub-sensors.

\begin{equation}
	\label{eqn:CovarianceMatrix}
	n_{sub} = \sum_{n=1}^{n_{cam}}n-1
\end{equation}

For these subsensor the metrological error can be described as an Ellipsoid $\mathbf{E}$ \cite{Luhmann2003} which corresponds to the covariance of the output quantities $\mathbf{\Lambda_{M}}$.

\begin{equation}
	\mathbf{E} = \mathbf{\Lambda_{M}} =
	\begin{bmatrix}
		\mathbf{S}_1^{} & \mathbf{S}_2^{} & \mathbf{S}_3^{}
	\end{bmatrix}^{\top}
	\begin{bmatrix}
		\lambda_1^{} & 0 \\
		0 & \lambda_2^{} &  0 \\
		0 & 0 &  \lambda_3^{}
	\end{bmatrix}
	\begin{bmatrix}
		\mathbf{S}_1^{} \\
		\mathbf{S}_2^{} \\
		\mathbf{S}_3^{}
	\end{bmatrix}
\end{equation}

The spectral decomposition of the covariance of the output quantities $\mathbf{\Lambda_{M}}$ leads to the Eigenvectors $\mathbf{S}_i$ and Eigenvalues $\lambda_i$, which correspond to the direction and length of the Ellipsoid.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\linewidth]{graphics/MixedErrorCuttingGeometry.eps}
	\caption{Blablabla 2}
	\label{fig:Ng2}
\end{figure}


%Established functional model \textit{Linear regression} ${\mathbf{I} + \mathbf{v} = \mathbf{J} \cdot \hat{x}} $


\begin{align}
	\label{eqn:LinRegModel}
	\hat{\mathbf{I}} = \mathbf{I} + \mathbf{v} = \mathbf{J} \hat{x} \\
	\hat{\mathbf{Q}} = \frac{1}{\sigma_{2}^{}}\mathbf{K} = \mathbf{P}
\end{align}

 can be written in a more general form \cite{Cox2006}:


\cite{Di_Leo_2011}
\cite{Liu_2021}

\begin{equation}
	\label{eqn:CovarianceMatrix}
	\Lambda = 
	\begin{bmatrix}
		e_{\delta_1}^2  & 0 & 0 & 0 & e_{(\delta_1,\delta_5)}^2 & 0 & 0 & 0 & 0 \\
		0  & e_{\delta_2}^2 & 0 & 0 & e_{(\delta_2,\delta_5)}^2 & 0 & 0 & 0 & 0 \\
		0 & 0 & e_{\delta_3}^2 & 0 & 0 & e_{(\delta_3,\delta_6)}^2 & 0 & 0 & 0 \\
		0 & 0 & 0 & e_{\delta_4}^2 & 0 & e_{(\delta_4,\delta_6)}^2 & 0 & 0 & 0 \\
		e_{(\delta_5,\delta_1)}^2 & e_{(\delta_5,\delta_2)}^2 & 0 & 0 & e_{\delta_5}^2 & 0 & 0 & 0 & 0 \\
		0 & 0 & e_{(\delta_6,\delta_3)}^2 & e_{(\delta_6,\delta_4)}^2 & 0 & e_{\delta_6}^2 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 & e_{\delta_7}^2 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & e_{\delta_8}^2 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & e_{\delta_9}^2
	\end{bmatrix}
\end{equation}

%literature review: with laser tracker: e.\,g.~\cite{Moeller17, Yang17}

%\begin{figure}[!htb]
%	\centering
%	\begin{subfigure}[b]{0.16\textwidth}
%		\centering
%		\includegraphics[width=0.5\linewidth]{graphics/ActiveMarkerSpatialOrientation.eps}
%		\caption{Blablabla 1}
%		\label{fig:Ng1} 
%	\end{subfigure}
%	\begin{subfigure}[b]{0.30\textwidth}
%		\centering
%		\includegraphics[width=1.0\linewidth]{graphics/ScatteringProfile_DiffuseFibreTip.eps}
%		\caption{Blablabla 2}
%		\label{fig:Ng2}
%	\end{subfigure}
%	\caption{Blabla.}
%\end{figure}

\subsection{Metrological Error Estimate}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=\columnwidth]{graphics/OpticalSimulation.eps}
	\caption{blabla}
\end{figure}

If the robot end effector is obscured and the optical measurement system cannot detect its pose (position and orientation), the pose of the endeffector is estimated using a Kalman filter with a constant velocity model. This assumption is reasonable in this case, as the measurement rate of the measurement system is significantly higher than the change in the pose of the endeffector.

je mehr Kameras, desto besser die Aufloesung
- natuerlicherweise so

- man braucht Strategie diese zu platzieren, siehe process strategies, camera placement 

so platzieren, dass sie das Target ueberhaupt sehen, nur damit bringen mehr Kameras auch Verbesserung

\section{Process Strategies}
\subsection{Hardware implementation} 

Kameras, Setup beschreiben (mehr als 2 Kameras wg. Abschattung, ergibt sich aus zuvor beschriebener Theorie)


of control system: robot w/ external sensor
calibration of camera system: interface ITO / ISYS
synchronized measurements of the camera, joint angles (encoders), joint torques 
interface through which the reference values for the joint space position, velocity and acceleration are directly communicated to the built-in robot trajectory tracking controller

pneumatic robot - direct drives, drive dynamics 

\subsection{overall strategy in software}
Kinematic and dynamic strategies need to be separated. 
In the field of robot trajectory generation, this has lead to the path speed decomposition framework~\cite{Choset05}, which is well known in the literature. 
Therein, first a path is generated kinematically, and second time-indexed considering the robot dynamics. 
kinematic errors vs. dynamic errors 

\subsection{Kinematic strategies:}
Some kinematic strategies for increasing the accuracy of industrial robots are already well-established.
Purely geometric errors in a robot can stem from the sources length deviations of links, axis misalignments and zero-position offsets of the encoders.
There are established methods for identifying and compensating these parameters in an offline calibration technique~\cite{Wiest01}.
To this end, the endeffector pose is measured, typically with a laser tracker, statically at certain points in the workspace and a certain number of times, and the geometric error parameters are determined in an optimization.
This offline calibration is usually performed at certain points and with specialized and expensive equipment, because of which it does not generalize in the entire workspace and is not applicable in the industrial robot application itself, but provides a first enhanced kinematic model of the robot.
From a kinematic point of view, if the manufacturing tolerances of the robot are known, incorporating them in the forward kinematics yields an error measure in task space. Such errors are usually much larger than the measurement accuracy of the presented measurement system.

also capture static deformation of the robot structure


\subsection{Path Planning}
There are severall error sources impeding the accuracy of a robotic manufacturing system.
An overview of these sources can be seen in Fig.~\ref{fig:error_sources}.
Most of these errors can be compensated using our external measurement system.

This leaves the finite precision of the robot itself, whose contribution can not be compensated but only mitigated.
Previous works such as \cite{previous_work} have shown that the optimal repeatability of a path is dependent on the workpiece placement.
This means that we can use the workpiece holding robot to reposition the workpiece in such a way that the optimal repeatability is achieved.
It might be tempting to try to find a continuous trajectory of this second robot to minimize the error.
However the second robot also suffers under finite joint precision, while moving these will introduce additional errors.
It is therefore better if the workpiece holding robot moves to a fixed position before the second robot starts moving.
This leads to a two step process similar to the one described in \cite{stroke_division}.
Here the authors propose a 4 step process to path planning:
\begin{enumerate}
  \item Cut path into multiple segments
  \item Downsample each segment
  \item Optimize the pose of each subpath and compute the joint path
  \item Apply the new pose to the original segments
\end{enumerate}
The division of the path into multiple segments was performed by identifying turning points using path simplification algorithms \cite{stroke_division}.
However instead of using the pose optimization algorithm described in \cite{stroke_division} we use the problem formulation of \cite{previous_work} since it allows us to integrate more constraints which are later used for the joint trajectory optimization.
% Hier ein Experiment durchführen mit den FESTO Robotern und zeigen wie sich die Genauigkeit gegen die Anzahl der Segmente verhält.
% Hier kann man dann als nächstes die Genauigkeit gegen die Taktzeit auftragen wenn man die Anzahl der Segmente variiert. Hier wird sich Pareto Kurve ergeben.


% The optimal Repeatability is dependent on the optimized kinematic parameters.




\subsection{Dynamic Strategies:} Ongoing Research \\
literature on capturing dynamic errors:

here: present robot's drives are direct drives, therefore no backlash in gearing, joint angle tracking error directly measured, 
enables dynamic error model
alternative: secondary encoders~\cite{Mesmer22}

closed loop control of the robot joints: tracking errors occur, but are captured in joint angle measurement

dynamic error model

data from measurement: same path executed at different speeds - dynamic error model is able to predict dynamic error of other velocity profile,

\begin{figure}[h]
	\centering
	\includegraphics[width=\columnwidth]{graphics/GP_eOf_dqDes_ddqDes_trainedOnFastestAndSlowest.png}
	\caption{Dynamic error in angle of one exemplary joint. Fit with dynamic Gaussian process error model considering the desired angular velocity and acceleration as features.}
	\label{fig:error_sources}
\end{figure}

low velocity: stick-slip from friction affects accuracy,\\
high velocity: limited bandwidth of the controller has the effect that tracking errors cannot be compensated well, also affects accuracy \\
therefore prefer medium velocity

allows for trade-off between process speed and accuracy

To find a compromise between accuracy and speed, the motion planning problem is divided into path planning and path trajectory generation. In path planning, the path of each of the robot's joint angles is computed, providing the highest possible repeatability. In trajectory generation, the previously computed path is indexed in time so that the robot can follow the given paths as quickly as possible such that the process speed is maximized, taking into account dynamic constraints of the robot (e.g. pressure build-up in the actuators).


next step: to incorporate in optimization

\subsection{Trajectory Generation}
The resulting path is time-indexed in the next step, i.\,e. a trajectory is generated from it

After the path has been determined in section XX under the premise of optimal repeatability, in this section a trajectory is generated based on the given path under the premise of maximizing the robot's travel speed and thus the process speed. To generate the trajectory, the already determined path of all joint angles is parameterized by a path parameter, so that the paths of the individual joints of the robot can be described by this parameter, whereby the individual paths are implicitly synchronized. Since Hoffmann et al. have already shown in XX that the robot with its drives is a differentially flat system, the states of the robot can be represented with the help of the given trajectory of the individual joint angles and the path parameter and its time derivatives. In order to generate the trajectory, it is now sufficient to determine the time derivatives of the path parameters by means of an optimal control problem in such a way that the travel time is minimized, taking into account the dynamic, state-dependent constraints of the robot.  For a more detailed description of trajectory generation, please refer to Kanagalingam et al. and their work XX.  


optimization-based
implemented: time-optimal, 

with accuracy in joint space

Outlook: Data-driven component added to the optimal control problem.
adding the mean value function of the Gaussian process

\subsection{Camera Placement}
here because requires entire robot configuration

After planning the path the two robots are bound to perform complex movements that might obscure some makers from the camera.
It might even be the case that all markers are visible but that they are in regions where the camera system has a low measurement accuracy.
To mitigate both problems we propose a software system that can optimize the placement of the cameras as needed.
This system is largely based on the work of \cite{camera_placement} and follows a two step optimization approach.
However instead of only considering the condition of the triangulation equation as well as visibility we use the full error model described in section \ref{error_estimate}.
This allows use to way the benefits of repositioning against the aditional effort needed to do reposition and recalibrate the system.
It also has practical advantages.
Replicating the results of \cite{camera_placement} where the smallest singular value was used as a measure of the quality of the camera placement we can additionally plot the largest angle to the optical axis.
Here we see that the system always tries to find a tradeoff between minimizing the field of view angle while trying to maximize the smallest singular value.
This is shown in Fig.~\ref{fig:fov_sv_conflict}.
In a unified error description this problem does not exist and the system can be optimized for the best possible accuracy.
\begin{figure}[h]
	\centering
	\includegraphics[width=\columnwidth]{graphics/fov_sv_conflict.png}
	\caption{The conflict between the field of view angle and the smallest singular value. Left: The smallest singular values of the system replicated from \cite{camera_placement}. Right: The largest angle of a marker to the optical axis.
		Comparing both one can see that lower singular values correlate with lower maximum field of view (FOV) angles.}
\end{figure}



\section{Outlook}
experimental validation of measurement system
- Outlook, Planing Invertation
- Tradeoff



\section{Online license transfer}
All authors are required to complete the Procedia exclusive license transfer agreement before the article can be published, which they can do online. This transfer agreement enables Elsevier to protect the copyrighted material for the authors, but does not relinquish the authors' proprietary rights. The copyright transfer covers the exclusive rights to reproduce and distribute the article, including reprints, photographic reproductions, microfilm or any other reproductions of similar nature and translations. Authors are responsible for obtaining from the copyright holder, the permission to reproduce any figures for which copyright exists.

\vfill\pagebreak

\section*{Acknowledgements}
The authors would like to thank the Ministry of Science, Research and Arts of the Federal State of Baden-Württemberg for the financial support of the projects within the InnovationsCampus Future Mobility (ICM).


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

\appendix
\section{An example appendix}
Authors including an appendix section should do so before References section. Multiple appendices should all have headings in the style used above. They will automatically be ordered A, B, C etc.


\bibliographystyle{elsarticle-harv}
\bibliography{sources}


%% Authors are advised to use a BibTeX database file for their reference list.
%% The provided style file elsarticle-num.bst formats references in the required Procedia style

%%%%%%%%%% If preparing manually:

%% For references without a BibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem[Clark et al.(1962)]{clark}Clark, T., Woodley, R., De Halas, D., 1962. Gas-Graphite Systems, in ``{\it Nuclear Graphite}''.
% In: Nightingale, R. (Ed.). Academic Press, New York, pp. 387.

% \bibitem[Deal and Grove(2009) ]{Deal}Deal, B., Grove, A., 1965. General Relationship for the Thermal Oxidation of Silicon. Journal of Applied Physics 36.2, 37--70.

% \bibitem[Deep(2009)]{Deep}Deep-Burn Project: Annual Report for 2009, Idaho National Laboratory, Sept. 2009.

% \bibitem[Fachinger(2004)]{Fachinger2004}Fachinger, J., den Exter, M., Grambow, B., Holgerson, S., Landesmann, C., Titov, M., Podruhzina, T., 2004. ``Behavior of spent HTR fuel elements in aquatic phases of repository host rock formations,'' 2nd International Topical Meeting on High Temperature Reactor Technology. Beijing, China, paper \#B08.

% \bibitem[Fachinger(2006)]{Fachinger2006}Fachinger, J., 2006. Behavior
% of HTR Fuel Elements in Aquatic Phases of Repository Host Rock Formations. Nuclear Engineering \& Design 236.3,      54.

% \end{thebibliography}

\clearpage\onecolumn

%%%% This page is for instructions only, once the article is finalize please omit the below text before creating the final PDF
\normalMode

\section*{Instructions to Authors for LaTeX template:}

\section{ZIP mode for LaTeX template:}

The zip package is created as per the guide lines present on the URL http://www.elsevier.com/author-schemas/ preparing-crc-journal-articles-with-latex for creating the LaTeX zip file of Procedia LaTeX template.  The zip generally contains the following files:
\begin{Itemize}[]\leftskip-12.7pt\labelsep3.3pt
\item ecrc.sty
\item  elsarticle.cls
\item elsdoc.pdf
\item .bst file
\item Manuscript templates for use with these bibliographic styles
\item  Generic and journal specific logos, etc.
\end{Itemize}

The LaTeX package is the main LaTeX template. All LaTeX support files are required for LaTeX pdf generation from the LaTeX template package.

{\bf Reference style .bst file used for collaboration support:} In the LaTeX template packages of all Procedia titles a new ``.bst'' file is used which supports collaborations downloaded from the path http://www.elsevier.com/author-schemas/the-elsarticle-latex-document-class

\end{document}

%%
%% End of file.
